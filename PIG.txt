Apache Pig is a high-level data flow platform for executing MapReduce programs of Hadoop. The language used for Pig is Pig Latin.

The Pig scripts get internally converted to Map Reduce jobs and get executed on data stored in HDFS. Apart from that, Pig can also execute its job in Apache Tez or Apache Spark.

Pig can handle any type of data, i.e., structured, semi-structured or unstructured and stores the corresponding results into Hadoop Data File System. Every task which can be achieved using PIG can also be achieved using java used in MapReduce.

Features of Apache Pig
Let's see the various uses of Pig technology.

1) Ease of programming
Writing complex java programs for map reduce is quite tough for non-programmers. Pig makes this process easy. In the Pig, the queries are converted to MapReduce internally.

2) Optimization opportunities
It is how tasks are encoded permits the system to optimize their execution automatically, allowing the user to focus on semantics rather than efficiency.

3) Extensibility
A user-defined function is written in which the user can write their logic to execute over the data set.

4) Flexible
It can easily handle structured as well as unstructured data.

5) In-built operators
It contains various type of operators such as sort, filter and joins.

---------------------------------------------------------------------------------------------------
Apache PIG
It is a high-level data flow tool.
It is not required to develop complex programs.
It provides built-in operators to perform data operations like union, sorting and ordering.
It provides nested data types like tuple, bag, and map.
----------------------------------------------------------------------------------------

Advantages of Apache Pig
Less code - The Pig consumes less line of code to perform any operation.
Reusability - The Pig code is flexible enough to reuse again.
Nested data types - The Pig provides a useful concept of nested data types like tuple, bag, and map.


-------------------------------------------
Pig Installation
-----------------------------
1)wget http://mirrors.estointernet.in/apache/pig/pig-0.16.0/pig-0.16.0.tar.gz

2)$ tar -xvzf pig-0.16.0.tar.gz  

3)
$ sudo nano ~/.bashrc  
export PIG_HOME=/home/hduser/pig-0.16.0  
export PATH=$PATH:$PIG_HOME/bin 

4)$ source ~/.bashrc  

5)$ pig -h  (Testing)

6)$ pig  
-----------------------------------------------------------------------------------

Pig Latin
-----------------------------
The Pig Latin is a data flow language used by Apache Pig to analyze the data in Hadoop.

Latin Data Types
---------------------------------------------
Simple Data Types

Type	Description
--------------------------------------------------
int	It defines the signed 32-bit integer.
	Example - 2
long	It defines the signed 64-bit integer.
	Example - 2L or 2l
float	It defines 32-bit floating point number.
	Example - 2.5F or 2.5f or 2.5e2f or 2.5.E2F
double	It defines 64-bit floating point number.
	Example - 2.5 or 2.5 or 2.5e2f or 2.5.E2F
chararray	It defines character array in Unicode UTF-8 format.
	Example - javatpoint
bytearray	It defines the byte array.
boolean	It defines the boolean type values.
	Example - true/false
datetime	It defines the values in datetime order.
	Example - 1970-01- 01T00:00:00.000+00:00
biginteger	It defines Java BigInteger values.
	Example - 5000000000000
bigdecimal	It defines Java BigDecimal values.
	Example - 52.232344535345
---------------------------------------------------------------------
Complex Types
-----------------------------------------
Type	Description
----------------------------------------
tuple	It defines an ordered set of fields.
	Example - (15,12)
bag	It defines a collection of tuples.
	Example - {(15,12), (12,15)}
map	It defines a set of key-value pairs.
	Example - [open#apache]
----------------------------------------------------------------------
Pig Data Types
--------------------------------
Apache Pig supports many data types. A list of Apache Pig Data Types with description and examples are given below.

Type	Description		Example
--------------------------------------------------------------------------------------------------
Int	Signed 32 bit integer		2
Long	Signed 64 bit integer		15L or 15l
Float	32 bit floating point		2.5f or 2.5F
Double	32 bit floating point		1.5 or 1.5e2 or 1.5E2
charArray	Character array		hello javatpoint
byteArray	BLOB(Byte array)	
tuple	Ordered set of fields		(12,43)
bag	Collection f tuples		{(12,43),(54,28)}
map	collection of tuples		[open#apache]
----------------------------------------------------------------------------------------------------
1)Apache Pig LOAD Operator
The Apache Pig LOAD operator is used to load the data from the file system.
---------------------------------------------------------------------
2)Apache Pig CROSS Operator
The Apache Pig CROSS operator facilitates to compute the cross product of two or more relations. Using CROSS operator is an expensive operation and should be used sparingly.
----------------------------------------------------
3)Apache Pig DISTINCT Operator
The Apache Pig DISTINCT operator is used to remove duplicate tuples in a relation. Initially, Pig sorts the given data and then eliminates duplicates.
----------------------------------------------------------------
4)Apache Pig FILTER Operator
The Apache Pig FILTER operator is used to remove duplicate tuples in a relation. Initially, Pig sorts the given data and then eliminates duplicates.
-----------------------------------------------------------
5)Apache Pig FOREACH Operator
The Apache Pig FOREACH operator generates data transformations based on columns of data. It is recommended to use FILTER operation to work with tuples of data.
--------------------------------------------------------------
6)Apache Pig Group Operator
The Apache Pig GROUP operator is used to group the data in one or more relations. 
------------------------------------------------------------------
7)Apache Pig LIMIT Operator
The Apache Pig LIMIT operator is used to limit the number of output tuples. 
-------------------------------------------------------------------------------
8)Apache Pig ORDER BY Operator
The Apache Pig ORDER BY operator sorts a relation based on one or more fields. It maintains the order of tuples.
----------------------------------------------------------------------
9)Apache Pig SPLIT Operator
The Apache Pig SPLIT operator breaks the relation into two or more relations according to the provided expression.
-------------------------------------------------------------------------
10)Apache Pig UNION Operator
The Apache Pig UNION operator is used to compute the union of two or more relations. It doesn't maintain the order of tuples. It also doesn't eliminate the duplicate tuples.
------------------------------------------------
example-1
---------------------
Create a text file in your local machine and write some values into it.
Upload both text files on HDFS in the specific directory.
Open the pig MapReduce run mode.
Load the file that contains the data.
Now, execute and verify the data.
Let's perform the union operation between both files.
Now, execute and verify the data.
------------------------------------
UNION

local user
step1 :- $ nano durga.txt  
step2 :-$ nano durgasoft.txt  
step3 :-hdfs dfs -put durga.txt /test
step4 :-hdfs dfs -put durgasoft.txt /test
pig
step1:-grunt>A = load '/test/durga.txt' using PigStorage(',') as (a1:int,a2:int);  
step2:-grunt>DUMP A;  
step3:-grunt>B = load '/test/durgasoft.txt' using PigStorage(',') as (a1:int,a2:int,a3:int);  
step4:-grunt>DUMP B;
step5:- grunt> Result = UNION A,B; 
step6:-grunt> DUMP Result;  
---------------------------------------------------------------------------------
split
-------------------
local
step1 :-$ nano split.txt  
step2 :-hdfs dfs -put split.txt /
--------
pig
grunt> A = LOAD '/split.txt' USING PigStorage(',') AS (a1:int,a2:int);  
grunt> DUMP A;  
grunt> SPLIT A INTO X IF a1<=2, Y IF a1>2;  
grunt> DUMP X;  
grunt> DUMP Y;  
---------------------------------------------------------------------------
ORDER BY
-------------------------
step1 :-$ nano order.txt  
step2 :-hdfs dfs -put order.txt /

pig
grunt> A = LOAD '/order.txt' USING PigStorage(',') AS (a1:int,a2:int);  
grunt> DUMP A
grunt> Result = ORDER A BY a1 DESC;  
grunt> Result = ORDER A BY a1 asc;  
grunt> DUMP Result;  
---------------------------------------------------------
Limit
-------------------
step1 :-$ nano limit.txt  
step2 :-hdfs dfs -put limit.txt /

pig
grunt> A = LOAD '/limit.txt' USING PigStorage(',') AS (a1:int,a2:chararray);  
grunt> DUMP A
grunt> Result = LIMIT A 2; 
grunt> DUMP Result;  
----------------------------------------------------------------
GROUPBY
----------------------------
step1 :-$ nano group.txt  
step2 :-hdfs dfs -put group.txt /

pig
grunt> A = LOAD '/group.txt' USING PigStorage(',') AS (name:chararray,address:chararray,dept:int);  
grunt> DUMP A
grunt> result = group A by dept;  
grunt>DUMP result;

o/p:-(10,{(ravi,bangalore,10),(KIRAN,bangalore,10),(sandip,bangalore,10)})
(20,{(arun,bangalore,20),(sunil,bangalore,20)})
--------------------------------------------- 
FOREACH
----------------------
pig
grunt> A = LOAD '/group.txt' USING PigStorage(',') AS (name:chararray,address:chararray,dept:int);  
grunt> DUMP A
grunt> result = FOREACH A generate name,address;  
grunt> DUMP result; 
------------------------------------------------------ 
FILTER
----------------
pig
grunt> A = LOAD '/group.txt' USING PigStorage(',') AS (name:chararray,address:chararray,dept:int);  
grunt> DUMP A
grunt> Result = FILTER A BY dept==10;   
grunt> DUMP Result; 
---------------------------------------------------------------------------
DISTINCT Operator
--------------------------------
pig
grunt> A = LOAD '/group.txt' USING PigStorage(',') AS (name:chararray,address:chararray,dept:int);  
grunt> DUMP A
grunt> Result = DISTINCT A;
grunt> DUMP Result;
-------------------------------------------------------------
CROSS Operator
-------------------------------
local user
step1 :- $ nano cross1.txt  
step2 :-$ nano cross2.txt  
step3 :-hdfs dfs -put cross1.txt /
step4 :-hdfs dfs -put cross2.txt /
pig
step1:-grunt>A = load '/cross1.txt' using PigStorage(',') as (a1:int,a2:int);  
step2:-grunt>DUMP A;  
step3:-grunt>B = load '/cross2.txt' using PigStorage(',') as (a1:int,a2:int,a3:int);  
step4:-grunt>DUMP B;
step5:- grunt> Result = CROSS A,B; 
step6:-grunt> DUMP Result;
------------------------------------------------------------------------ 
Avg function
------------------------------
step1 :-$ nano avg.txt  
step2 :-hdfs dfs -put avg.txt /

pig
grunt> A = LOAD '/avg.txt' USING PigStorage(',') AS (name:chararray,address:chararray,salary:int);  
grunt> DUMP A
grunt> B = GROUP A BY address;   
grunt> DUMP B;
grunt> Result = FOREACH B GENERATE A.name, AVG(A.salary);  
grunt> DUMP Result;  
-------------------------------------------------------------------
concat function
----------------------------------
1)nano concat.txt  
2)hdfs dfs -put concat.txt /

pig
--------------------------------------------------------------------------------
1)grunt> A = LOAD '/concat.txt' USING PigStorage(',') AS (a1:chararray,a2:chararray,a3:int); 
2)grunt> DUMP A; 
3)Result = FOREACH A GENERATE CONCAT (a1,'_',a2);   
4)DUMP Result;  
------------------------------------------------------------

COUNT Function
----------------------------------
1)nano count.txt
2)$ hdfs dfs -put count.txt /

pig
---------
1)grunt> A = LOAD '/count.txt' USING PigStorage(',') AS (a1:int,a2:int,a3:int) ;  
2)grunt> DUMP A; 
3)grunt> B = GROUP A BY a1;   
4)grunt> DUMP B; 
5)grunt> Result = FOREACH B GENERATE COUNT(A);  
6)grunt> DUMP Result;
------------------------------------------------------------------------------
IN Function
-----------------------------
1)$ nano in.txt
2)$ hdfs dfs -put in.txt /

pig
--------------
1)grunt> A = LOAD '/in.txt' USING PigStorage(',') AS (a1:int,a2:chararray,a3:chararray) ;    

2)grunt> DUMP A;  
3)grunt> Result = FILTER A BY a1 IN (2, 4);  
4)grunt> DUMP Result; 
-------------------------------------------------------------------------------------------
MAX Function
--------------------------------
1)$ nano max.txt  
2)hdfs dfs -put max.txt /

pig
1)grunt> A = LOAD '/max.txt' USING PigStorage(',') AS (a1:chararray,a2:chararray,a3:float) ;

2)grunt> DUMP A;
3)grunt> B = GROUP A BY a1;   
4)grunt> DUMP B;
5)grunt> Result = FOREACH B GENERATE group, MAX(A.a3);  
6)grunt> DUMP Result;  
---------------------------------------------------------------
MIN Function
--------------------------------
1)$ nano min.txt  
2)hdfs dfs -put min.txt /

pig
1)grunt> A = LOAD '/min.txt' USING PigStorage(',') AS (a1:chararray,a2:chararray,a3:float) ;

2)grunt> DUMP A;
3)grunt> B = GROUP A BY a1;   
4)grunt> DUMP B;
5)grunt> Result = FOREACH B GENERATE group, MIN(A.a3);  
6)grunt> DUMP Result;  
----------------------------------------------------------------------------------------------
SIZE Function(character size)
---------------------------------
step 1:nano size.txt
step 2:hdfs dfs -put size.txt /

pig
---------
1)grunt> A = LOAD '/size.txt' USING PigStorage(',') AS (a1:chararray,a2:chararray) ;    
2)grunt> DUMP A; 
3)grunt> Result = FOREACH A GENERATE SIZE(a1);  
4)grunt> DUMP Result;  
----------------------------------------------------------------------------
SUM Function
-----------------------------
1)nano sum.txt 
2)hdfs dfs -put sum.txt /

pig
1)grunt> A = LOAD '/sum.txt' USING PigStorage(',') AS (a1:chararray,a2:chararray,a3:float) ;

2)grunt> B = GROUP A BY a1;   
3)grunt> DUMP B;  
4)grunt> Result = FOREACH B GENERATE group, SUM(A.a3);  
5)grunt> DUMP Result;  
------------------------------------------------------------------------------------------
TOKENIZE Function
----------------------------------
step 1:nano tokenize.txt
step 2:hdfs dfs -put tokenize.txt /

pig
1)grunt> A = LOAD '/tokenize.txt' USING PigStorage(',') AS (a1:chararray) ;   
2)grunt> DUMP A;
3)grunt> Result = FOREACH A GENERATE TOKENIZE(a1);  
4)grunt> DUMP Result;    