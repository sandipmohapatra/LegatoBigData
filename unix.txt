

Linux is an open-source operating system. 
Unix is also an operating system like Linux. It is an commercial OS. 

It consists of three parts: Kernal, Shell and Programs. 

In the simple language Linux is an operating system (OS). We all are familiar with other operating systems like Microsoft windows, Apple Mac OS, iOS, Google android, etc, just like them linux is also an operating system.


Structure Of Linux Operating System
Linux OS has following components:

1) Kernel
kernel is the core of the operating system. It establishes communication between devices and software.

 Basically it has four responsibilities:

device management: A system has many devices connected to it like CPU, memory device, sound cards, graphic cards, etc. A kernel stores all the data related to all the devices in device driver.

Memory management: Another function that kernel has to manage is the memory management. Kernel keeps a track of used and unused memory and make sure that processes shouldn't manipulate data of each other using virtual memory address.

Process management: In process management kernel assign enough time and gives priorities to processes before handling CPU to other process. It also deals with security and ownership information.

Handling system calls: Handling system calls means a programmer can write a query or ask the kernel to perform a task.

2) System Libraries
System libraries are special programs that helps in accessing the kernel's features. It is used to perform any task.

3) System Tools
Linux OS has a set of utility tools. With the help of commands you can access your files, edit and manipulate data in your directories or files, change location of files or anything.

4) Development Tools
The additional tools and libraries are written by the programmers to produce a working application is known as development tools.

5) End User Tools
These end tools make a system unique for a user. End tools are not required for the operating system but are necessary for a user.

Some examples of end tools are graphic design tools, office suites, browsers, multimedia players, etc.
-----------------------------------------------
to create directory
mkdir <directory name>
-------------------------------------------
to change directory
cd <directory name>
---------------------------------------------
to come out of the directory
cd ..
----------------------------------------
to create a file
vi <filename>
to insert data
press insert 
to save and exit 
esc :wq
--------------------------------------
to view the data
cat <filename>
-----------------------------------
to view the list of files and directory present under a directory
ls - l
---------------------------------------------
https://github.com/sandipmohapatra/LegatoBigData
------------------------------------------------
cat file1 file2 > files Combine file1 and file2 into files 
------------------------------------------------------------------
cat file1 >> file2 Append file1 at the end of file2 
--------------------------------------------------------------------------
chmod [options] mode files

Change the access mode of one or more files. 
Only the owner or privileged user may change its mode. 
Create mode by concatenating who, opcode and  permission.
who (u­ user)(g­group)(o­other)(a­all) opcode (+ add permission)
(­remove permission)(= assign permission, and  remove from the not assigned) permission (r or 4 – read)(w or 2 – write)(x or 1 – execute)

Examples: chmod u+x file (add permission to the user to execute the file) chmod 751 file (chmod u=rwx, g=rx, o=x file) 

-----------------------------------------------
cmp file1 file2 Compare two files (0­identical)(1­different)(2­inaccessible) 
----------------------------------------------------------
clear:- clear the terminal display 
date :- to view the date
time :- to view the time
--------------------------------------------------------

cmp file1 file2 :- Compare two files (0­identical)(1­different)(2­inaccessible)
-----------------------------------------------------------------
10)ls [options] [names] 

­a     list all files, including the hidden . files. --d     list only directory information, not its contents. Used with ­l. -h     human readable, using abbreviations for kilobyte, megabyte, etc. -k     size in kilobytes -l     long format list (includes permissions, owner, size, modification time, etc). -r     list files in reverse order (by name or by time). -R    recursively list subdirectories. s      list size in blocks (1block = 512 KB) -t     list files according to modification time (newest first) -u    list files according to the file access time.
--------------------------
11)cp file1 file2 
12) vi editor
i	Start typing before the current character
I	Start typing at the start of current line
a	Start typing after the current character
A	Start typing at the end of current line
o	Start typing on a new line after the current line
O	Start typing on a new line before the current line
j	To move down
k	To move up
h	To move left
l	To move right
x	Delete the current character
X	Delete the character before the cursor
r	Replace the current character
xp	Switch two characters
dd	Delete the current line
D	Delete the current line from current character to the end of the line
dG	delete from the current line to the end of the file
u	Undo the last command
.	Repeat the last command
dd	Delete a line
yy	(yank yank) copy a line
p	Paste after the current line
P	Paste before the current line
--------------------------------------------------------------------------------------
to encrypt
gpg -c first
---------------------------------
To decrypt file :
gpg --output <new filename> --decrypt <filename>.gpg
-------------------------------------------------------------
cal - display the calander
--------------------------------------------
cal <month> <year>- display the calander and year
---------------------------------------------------------------------------
grep :- to search the content in a file

grep <text> <filename>
-------------------------------------------------------
cat <filename> | grep text
--------------------------------------------------
The 'grep -v' command displays lines not matching to the specified word.
-----------------------------------------------------------
The 'grep -i' command filters output in a case-insensitive way.
--------------------------------------------------------------------------------
word count
------------------------------------------------------------------------------
wc <fileName>         (Counts line,words and characters)  
wc -l <fileName>      (Counts only lines)  
wc -w <fileName>     (Counts only words)  
wc -c <fileName>      (Counts only characters)  
--------------------------------------------------------------------------------------
pwd :- displays your location currently you are working on.
----------------------------------------------------------------------------
rmdir <dirname> :-delete a directory
There should not be any files inside it.if file is present you have to enter into the directory .Delete the files.come out of the directory and delete the directory.
* to remove file (rm <filename>)
----------------------------------------------------------------
cut 
----------
cut -d(delimiter) -f(columnNumber) <fileName>  

cut -d- -f(columnNumber) <fileName>  

cut -d- -f2 first.txt  
cut -d- -f1 first.txt  

------------------------------------
The 'comm' command compares two files . 
'comm' will always display three columns.
First column indicates non-matching items of first file, 
second column indicates non-matching items of second file, 
and third column indicates matching items of both the files.
Both the files has to be in sorted order for 'comm' command to be executed.

comm <file1> <file2>
----------------------------------------------
sort 
sort <filename>
sort <filename> > <new filename>(output will be redirect to another file)

sort -k<columnNumber> <fileName>   
sort -k1 first.txt 

----------------------------------
man ls (help file)
to exit press x
-------------------------------------
diff <file1><file>
-----------------------------------------
to see first 2 lines of a file
head -2 <filename>
------------------------------------
to see last 2 lines of a file
tail -2 <filename>
-------------------------------------
whoami  :- it will display the user name
----------------------------------------------------------------
uniq :- it will display the non uniq values only.

sort a1 | uniq
-----------------------------------------------------------------
gzip <file1> <file2>
gunzip <file1> <file2> 
-----------------------------------------------
# Update the source list
k@laptop:~$ sudo apt-get update
# The OpenJDK project is the default version of Java 
# that is provided from a supported Ubuntu repository.
k@laptop:~$ sudo apt-get install default-jdk

k@laptop:~$ java -version
java version "1.7.0_65"
OpenJDK Runtime Environment (IcedTea 2.5.3) (7u71-2.5.3-0ubuntu0.14.04.1)
OpenJDK 64-Bit Server VM (build 24.65-b04, mixed mode)
-----------------------------------------
Adding a dedicated Hadoop group
k@laptop:~$ sudo addgroup hadoop
---------------------------------------------------------------------------
Adding user
k@laptop:~$ sudo adduser --ingroup hadoop hduser
------------------------------------------------------------------------------
Installing SSH(protocal to communicate between master and slave) 
ssh : The command we use to connect to remote machines and the client.
sshd : The daemon that is running on the server and allows clients to connect to the server.

k@laptop:~$ sudo apt-get install ssh
-------------------------------------------------------------
Create and Setup SSH Certificates
---------------------------------------------------
Hadoop requires SSH access to manage its nodes, i.e. remote machines plus our local machine. we therefore need to configure SSH access to localhost.

So, we need to have SSH up and running on our machine and configured it to allow SSH public key authentication.

Hadoop uses SSH (to access its nodes) which would normally require the user to enter a password. However, this requirement can be eliminated by creating and setting up SSH certificates using the following commands. If asked for a filename just leave it blank and press the enter key to continue.
----------------------------------------------------------------
to login for user
-------------------------
su hduser
password
--------------------------------------------
to generate password
------------------------------------
ssh-keygen -t rsa -P ""
----------------------------------------------------------------------------------------
down load and install hadoop
 --------------------------------------------
download
1) hduser@laptop:~$ wget http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz
------------------------
install
2)hduser@laptop:~$ tar xvzf hadoop-2.6.5.tar.gz
--------------------------------------------------------------------------------------------------
to change user
-------------------------
su <username>
su hduser
----------------------------------------------
change use to previous user
su sandip
---------------------------------------------------
add sudo permision to hduser 
sudo adduser hduser sudo
------------------------------------------------------
move  the installed s/w to another folder and give owner permission
----------------------------------------------------------------------------------------
hduser@laptop:~/hadoop-2.6.5$ sudo mv * /usr/local/hadoop 
hduser@laptop:~/hadoop-2.6.5$ sudo chown -R hduser:hadoop /usr/local/hadoop
-----------------------------------------------------------------
Setup Configuration Files
------------------------------------------------------------------
~/.bashrc
/usr/local/hadoop/etc/hadoop/hadoop-env.sh
/usr/local/hadoop/etc/hadoop/core-site.xml
/usr/local/hadoop/etc/hadoop/mapred-site.xml.template
/usr/local/hadoop/etc/hadoop/hdfs-site.xml
------------------------------------------------------------------------------------------------
Now we can append the following to the end of ~/.bashrc:

hduser@laptop:~$ vi ~/.bashrc

#HADOOP VARIABLES START
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
export HADOOP_INSTALL=/usr/local/hadoop
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
#HADOOP VARIABLES END

hduser@laptop:~$ source ~/.bashrc
------------------------------------------------------------------------------------------------------
note that the JAVA_HOME should be set as the path just before the '.../bin/':

hduser@ubuntu-VirtualBox:~$ javac -version
javac 1.7.0_75

hduser@ubuntu-VirtualBox:~$ which javac
/usr/bin/javac

hduser@ubuntu-VirtualBox:~$ readlink -f /usr/bin/javac
/usr/lib/jvm/java-7-openjdk-amd64/bin/javac
--------------------------------------------------------------------------------------------------------

2. /usr/local/hadoop/etc/hadoop/hadoop-env.sh

We need to set JAVA_HOME by modifying hadoop-env.sh file.

hduser@laptop:~$ vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh

export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
Adding the above statement in the hadoop-env.sh file ensures that the value of JAVA_HOME variable will be available to Hadoop whenever it is started up.

------------------------------------------------------------------------------------------------

3. /usr/local/hadoop/etc/hadoop/core-site.xml:

The /usr/local/hadoop/etc/hadoop/core-site.xml file contains configuration properties that Hadoop uses when starting up. 
This file can be used to override the default settings that Hadoop starts with.

hduser@laptop:~$ sudo mkdir -p /app/hadoop/tmp
hduser@laptop:~$ sudo chown hduser:hadoop /app/hadoop/tmp
Open the file and enter the following in between the <configuration></configuration> tag:

hduser@laptop:~$ vi /usr/local/hadoop/etc/hadoop/core-site.xml

<configuration>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/app/hadoop/tmp</value>
  <description>A base for other temporary directories.</description>
 </property>

 <property>
  <name>fs.default.name</name>
  <value>hdfs://localhost:54310</value>
  <description>The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.</description>
 </property>
</configuration>

---------------------------------------------------------------------------------------------------------------
4. /usr/local/hadoop/etc/hadoop/mapred-site.xml

By default, the /usr/local/hadoop/etc/hadoop/ folder contains 
/usr/local/hadoop/etc/hadoop/mapred-site.xml.template 
file which has to be renamed/copied with the name mapred-site.xml:

hduser@laptop:~$ cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml
The mapred-site.xml file is used to specify which framework is being used for MapReduce.
We need to enter the following content in between the <configuration></configuration> tag:

<configuration>
 <property>
  <name>mapred.job.tracker</name>
  <value>localhost:54311</value>
  <description>The host and port that the MapReduce job tracker runs
  at.  If "local", then jobs are run in-process as a single map
  and reduce task.
  </description>
 </property>
</configuration>

---------------------------------------------------------------------------------------------------------------

5. /usr/local/hadoop/etc/hadoop/hdfs-site.xml

The /usr/local/hadoop/etc/hadoop/hdfs-site.xml file needs to be configured for each host in the cluster that is being used. 
It is used to specify the directories which will be used as the namenode and the datanode on that host.

Before editing this file, we need to create two directories which will contain the namenode and the datanode for this Hadoop installation. 
---------------------------------------------------------------------------------------------------------
This can be done using the following commands:

hduser@laptop:~$ sudo mkdir -p /usr/local/hadoop_store/hdfs/namenode
hduser@laptop:~$ sudo mkdir -p /usr/local/hadoop_store/hdfs/datanode
hduser@laptop:~$ sudo chown -R hduser:hadoop /usr/local/hadoop_store



----------------------------------------------------------------------------------------------------





   


























