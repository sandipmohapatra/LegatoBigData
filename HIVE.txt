
Hive is a data warehouse system which is used to analyze structured data. It is built on the top of Hadoop. It was developed by Facebook.

Hive provides the functionality of reading, writing, and managing large datasets residing in distributed storage. It runs SQL like queries called HQL (Hive query language) which gets internally converted to MapReduce jobs.

Using Hive, we can skip the requirement of the traditional approach of writing complex MapReduce programs. Hive supports Data Definition Language (DDL), Data Manipulation Language (DML), and User Defined Functions (UDF).

Features of Hive
These are the following features of Hive:

Hive is fast and scalable.
It provides SQL-like queries (i.e., HQL) that are implicitly transformed to MapReduce or Spark jobs.
It is capable of analyzing large datasets stored in HDFS.
It allows different storage types such as plain text, RCFile, and HBase.
It uses indexing to accelerate queries.
It can operate on compressed data stored in the Hadoop ecosystem.
It supports user-defined functions (UDFs) where user can provide its functionality.

Limitations of Hive
------------------------------------
Hive is not capable of handling real-time data.
It is not designed for online transaction processing.
Hive queries contain high latency.
-----------------------------------------------
Differences between Hive and Pig


Hive	
Hive is commonly used by Data Analysts.	
It follows SQL-like queries.	
It can handle structured data.	
It works on server-side of HDFS cluster.	
Hive is slower than Pig.	


Pig
Pig is commonly used by programmers.
It follows the data-flow language.
It can handle semi-structured data.
It works on client-side of HDFS cluster.
Pig is comparatively faster than Hive.

----------------------------------------------------------------------------
install hive
------------------------
1)wget http://mirrors.estointernet.in/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz  

2)tar -xvzf apache-hive-1.2.2-bin.tar.gz  

3)sudo nano ~/.bashrc 

export HIVE_HOME=/home/hduser/apache-hive-1.2.2-bin  
export PATH=$PATH:/home/hduser/apache-hive-1.2.2-bin/bin  
export HADOOP_USER_CLASSPATH_FIRST=true
---------------------------------
4) source ~/.bashrc

5)hive
---------------------------------------------------------------
data types
--------------------------------------------------------------
TINYINT		1-byte signed integer	
SMALLINT	2-byte signed integer	
INT		4-byte signed integer	
BIGINT		8-byte signed integer
FLOAT		4-byte	
DOUBLE		8-byte

-------------------------------------------------------------
Complex Type
--------------------------------------------------------------
Struct	struct('sandip','kumar')
Map 	map('first','sandip','last','kumar')
Array	array('sandip','kumar')

-------------------------------------------------------------------------------------------------------
String Types
----------------------------------
STRING
The string is a sequence of characters. It values can be enclosed within single quotes or double quotes .

Varchar
The varchar is a variable length type whose range lies between 1 and 65535.

CHAR
The char is a fixed-length type whose maximum length is fixed at 255.

---------------------------------------------------------------------------------------------
HIVE Partitioning

Table partitioning means dividing table into some parts based on values of a particular column like date or country, segregate the records into different files.
It can be done on more than one column. The advantage of partioning is that since the data is stored in slices query response time is faster.

-------------------------------------------------------------------------------------------
CREATE TABLE STUDENT (ROLLNO INT, NAME STRING) PARTITIONED BY (STREAM STRING);  

Hive Commands
Hive supports Data definition Language(DDL), Data Manipulation Language(DML) and User defined functions.

Hive DDL Commands
create database,drop database,create table,drop table,alter table
create index,create views

Hive DML Commands
Select,Where,Group By,Order By,Load Data,
Join:Inner Join,Left Outer Join,Right Outer Join,Full Outer Join
------------------------------------------------------------------------------------------------------
1)hive> CREATE SCHEMA LEGATO;  

2)hive> SHOW DATABASES;  

3)hive> DROP DATABASE IF EXISTS LEGATO;

4)hive> CREATE TABLE STUDENT(ROLLNO INT, NAME STRING,ADDRESS STRING);

5)hive>  Show tables;  

6)hive>  INSERT INTO STUDENT VALUES(101,'SANDIP','HYD'); 

7)hive>  SELECT * FROM STUDENT;

8)hive> ALTER TABLE STUDENT RENAME TO EMPLOYEE;  

9)hive> ALTER TABLE EMPLOYEE ADD COLUMNS (ACCNO INT);

10)hive> SELECT  E.ROLLNO FROM Employee E  WHERE E.Address='HYD';

11)hive> SELECT  E.ROLLNO FROM Employee E GROUP BY E.Addresss;     

12)hive> SELECT  ROLLNO FROM Employee E SORT BY E.ROLLNO;

13)hive> SELECT  E.ROLLNO FROM Employee E order BY E.ROLLNO;
-----------------------------------------------------------------------------------------
import java.sql.SQLException;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.Statement;
import java.sql.DriverManager;

public class HiveCreateDb {
   private static String driverName = "org.apache.hadoop.hive.jdbc.HiveDriver";
   
   public static void main(String[] args) throws SQLException {
      // Register driver and create driver instance
   
      Class.forName(driverName);
      // get connection
      
      Connection con = DriverManager.getConnection("jdbc:hive://localhost:10000/default", "", "");
      Statement stmt = con.createStatement();
      
      stmt.executeQuery("CREATE DATABASE userdb");
      System.out.println(“Database userdb created successfully.”);
      
      con.close();
   }
}
 ----------------------------------------------------------------------------------------------
String function

14)hive> select CONCAT('concat','->','demo');
OK
concat->demo

15)hive> select substr('This is hive demo',9,4);
OK
hive

16)hive> select length('hadoop');
OK
6

17)hive> select upper('hadoop'), ucase('hadoop');
OK
HADOOP HADOOP

18)hive> select lower('HADOOP'), lcase('HADOOP');
OK
hadoop hadoop

19)hive> select lpad('hadoop',8,'H');
OK
Hhhadoop

20)hive> select rpad(‘hadoop’,8,’p’);
OK
hadooppp

21)hive> select trim(' Hadoop ');
OK
'Hadoop'

22)hive> select ltrim(' Hadoop ');
OK
'Hadoop '

23)hive> select rtrim(' Hadoop ');
OK
' Hadoop'

24)hive> select repeat('Hadoop',2);
OK
HadoopHadoop

25)hive> select reverse('Hadoop');
OK
poodaH

26)hive> select split('hadoop~supports~split~function','~');
OK
["hadoop","supports","split","function"]

---------------------------------------------------------------------------------------
Date Function

hive> select current_timestamp();
OK
2017-10-01 00:54:14.736
Time taken: 0.65 seconds, Fetched: 1 row(s)

hive> select current_date();
OK
2017-10-01
Time taken: 0.161 seconds, Fetched: 1 row(s)
Add 1 day to current date using HiveQL

hive> select date_add(current_date(), 1);
OK
2017-10-02
Time taken: 0.123 seconds, Fetched: 1 row(s)
Subtract 1 day from current date using HiveQL

hive> select date_sub(current_date(),1);
OK
2017-09-30
Time taken: 0.107 seconds, Fetched: 1 row(s)
Get first day of the given timstamp using HiveQL

hive> select trunc(current_timestamp(), 'MONTH');
OK
2017-10-01
Time taken: 0.072 seconds, Fetched: 1 row(s)
Convert timestamp to date format using HiveQL

hive> select to_date(current_timestamp());
OK
2017-10-01
Time taken: 0.08 seconds, Fetched: 1 row(s)
Data type conversion using Cast function in HiveQL

hive> select cast(current_timestamp() as date);
OK
2017-10-01
Time taken: 0.094 seconds, Fetched: 1 row(s)
Convert Timestamp to YYYYMMDD format using HiveQL

hive> select from_unixtime(unix_timestamp(current_date()), 'yyyymmdd');
OK
20170001
Time taken: 0.078 seconds, Fetched: 1 row(s) 
------------------------------------------------------------------------------------      